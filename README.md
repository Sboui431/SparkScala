# SparkScala
Apache Spark Scala
Dies ist eine Belegaufgabe im Rahmen unseres Studiums an der HTW Berlin im Master Angewadte Informatik . Im Kurs ProgrammierKonzepte und Algorithmen arbeiten wir an Aufgabe 12. Es liegt ein Datensatz von 502 TextDateien –untertteilt in 8 Sprachen. Ziel ist es , mit Apache Spark diese Texte zu analysieren und dabei drei Aufgaben zu erfüllen :
a)	Zählen der Wörterlänge (Pro Sprache)
b)	Sortieren der Wörter der Länge nach (Pro Sprache )
c)	Zusammenfassen der Ergebnisse
  Dabei soll eine Ausgabe in der Form : „ Sprache – Längste Wort – Länge“
